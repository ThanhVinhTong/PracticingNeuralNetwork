{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1uuVVCvLt0Z"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets --upgrade -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmASB_9nAvxH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import copy\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import opendatasets as od"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "R149Ko3WCVtG",
        "outputId": "ef5eb4ea-8f37-4ff2-e6a7-5e93dc1a8501"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nCIFAR100\\n100 classes containing 600 images each. \\nThere are 500 training images and 100 testing images per class. \\nThe 100 classes in the CIFAR-100 are grouped into 20 superclasses.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "\"\"\"\n",
        "CIFAR100\n",
        "100 classes containing 600 images each. \n",
        "There are 500 training images and 100 testing images per class. \n",
        "The 100 classes in the CIFAR-100 are grouped into 20 superclasses.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvuwWDGxDy7i"
      },
      "outputs": [],
      "source": [
        "#_______________________________Preparing the data__________________________\n",
        "batch_size = 400\n",
        "num_workers = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nSLdyHtMKSj",
        "outputId": "0fa34686-1f11-4f9b-b6a7-abb3f8293b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./cifar-100-images\" (use force=True to force download)\n"
          ]
        }
      ],
      "source": [
        "dataset_url = 'https://www.kaggle.com/minbavel/cifar-100-images'\n",
        "od.download(dataset_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = './cifar-100-images/CIFAR100/TRAIN'\n",
        "print(\"Number of categories in CIFAR100 are {}\".format(len(os.listdir(data_dir))))\n",
        "# As we have around 50000 images across 100 categories, lets keep 20% images, i.e 10000 images to validation\n",
        "# this creates all required folders, such as Val and their subfolders\n",
        "val_path = './cifar-100-images/CIFAR100/VAL'\n",
        "source_dir = './cifar-100-images/CIFAR100/TRAIN'\n",
        "os.mkdir(val_path)\n",
        "\n",
        "for i in sorted(os.listdir(source_dir)):\n",
        "  path = val_path+'/'+i\n",
        "  os.mkdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "aS9S3KtyZMeN",
        "outputId": "ee4f86b4-33f7-4bee-efa6-f2d981cbbea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of categories in CIFAR100 are 100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-fea741f4442d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./cifar-100-images/CIFAR100/VAL'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msource_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./cifar-100-images/CIFAR100/TRAIN'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './cifar-100-images/CIFAR100/VAL'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "xV_PufQAMpRr",
        "outputId": "89b0c2ae-8130-4d7b-d741-9e8463a84405"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-812b17524a37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# print(\"Random Integers \\n\",randint)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msource_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msource_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mdest_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdest_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msource_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_file_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdest_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "for folder in sorted(os.listdir(source_dir)):\n",
        "    dest_path = val_path+'/'+folder\n",
        "    source_path = source_dir+'/'+folder\n",
        "\n",
        "    source_files = os.listdir(source_path)\n",
        "    randint = sorted(random.sample(range(500), 100))\n",
        "    # print(\"Random Integers \\n\",randint)\n",
        "    for file in randint:\n",
        "        source_file_name = source_path+'/'+source_files[file]\n",
        "        dest_file_name = dest_path+'/'+source_files[file]\n",
        "        os.rename(source_file_name,dest_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1qzdFHI1hT3"
      },
      "outputs": [],
      "source": [
        "print(\"Number of files in Train folder are {}\".\n",
        "format(sum([len(os.listdir(data_dir+'/'+x)) for x in os.listdir(data_dir)])))\n",
        "print(\"Number of files in Validation folder are {}\".\n",
        "format(sum([len(os.listdir(val_path+'/'+x)) for x in os.listdir(val_path)])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUf7sZwGNQ9h"
      },
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        "    'TRAIN': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5071, 0.4866, 0.4409], [0.2673, 0.2564, 0.2762])\n",
        "    ]),\n",
        "    'VAL': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5071, 0.4866, 0.4409], [0.2673, 0.2564, 0.2762])\n",
        "    ]),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PDR6nwmOBvz"
      },
      "outputs": [],
      "source": [
        "data_dir = './cifar-100-images/CIFAR100/'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['TRAIN', 'VAL']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=128,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['TRAIN', 'VAL']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['TRAIN', 'VAL']}\n",
        "class_names = image_datasets['TRAIN'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv_MBzlcOV_l"
      },
      "outputs": [],
      "source": [
        "#___________________writing helper function to display a sample of images.________________________________\n",
        "inputs, classes = next(iter(dataloaders['TRAIN']))\n",
        "\n",
        "\n",
        "def denormalize(images, means, stds):\n",
        "    means = torch.tensor(means).reshape(1, 3, 1, 1)\n",
        "    stds = torch.tensor(stds).reshape(1, 3, 1, 1)\n",
        "    return images * stds + means\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "ax.set_xticks([]); ax.set_yticks([])\n",
        "denorm_images = denormalize(inputs, [0.5071, 0.4866, 0.4409],[0.2673, 0.2564, 0.2762])\n",
        "ax.imshow(torchvision.utils.make_grid(denorm_images[:64], nrow=8).permute(1, 2, 0).clamp(0,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNKTRKqgOrBj"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.5071, 0.4866, 0.4409])\n",
        "    std = np.array([0.2673, 0.2564, 0.2762])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['TRAIN']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs,nrow=8)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyQy1PnZPhNn"
      },
      "outputs": [],
      "source": [
        "#__________________Train using GPU__________________\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBxCtDTNQALM"
      },
      "outputs": [],
      "source": [
        "save_train_loss = []\n",
        "save_val_loss = []\n",
        "save_train_acc = []\n",
        "save_val_acc = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOWEy6IvQFIp"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['TRAIN', 'VAL']:\n",
        "            if phase == 'TRAIN':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'TRAIN'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'TRAIN':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'VAL' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUUbCTQccWcj"
      },
      "outputs": [],
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['VAL']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBC2-CkQ4Hx6"
      },
      "outputs": [],
      "source": [
        "models.resnet50(pretrained=True).fc.in_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Jc0GO2kdpwk"
      },
      "outputs": [],
      "source": [
        "model_ft = models.resnet50(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u77wmSp_d8sb"
      },
      "outputs": [],
      "source": [
        " model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Resnet50(SGD)_Cifar100.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}